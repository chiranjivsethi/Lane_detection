{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_images = pickle.load(open(\"data/full_CNN_train.p\", \"rb\" ))\n",
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"data/full_CNN_labels.p\", \"rb\" ))\n",
    "\n",
    "# Make into arrays as the neural network wants these\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize labels - training images get normalized to start in the network\n",
    "labels = labels / 255\n",
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Normalizes incoming inputs. First layer needs the input shape to work\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    # Below layers were re-named for easier reading of model summary; this not necessary\n",
    "    # Conv Layer 1\n",
    "    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # Pooling 1\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 3\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 4\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 5\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Pooling 2\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 6\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 7\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Pooling 3\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Upsample 1\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 1\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 2\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Upsample 2\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 3\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 4\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 5\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Upsample 3\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 6\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "    # Final layer - only including one channel so 1 filter\n",
    "    model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "    ### End of network ###\n",
    "    \n",
    "    model.compile(optimizer='Adam', loss='mean_squared_error',metrics = [\"accuracy\"])\n",
    "    \n",
    "    print(\"MODEL CREATED\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit_model():\n",
    "    model_hist = model.fit(X_train, Y_train, batch_size=64, epochs=epochs)\n",
    "    return model_hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL CREATED\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 80, 160, 3)        12        \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 78, 158, 8)        224       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 76, 156, 16)       1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 36, 76, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 36, 76, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 34, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 34, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 32, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 32, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv6 (Conv2D)               (None, 14, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 14, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv7 (Conv2D)               (None, 12, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 12, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 6, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 12, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv1 (Conv2DTranspose)    (None, 14, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 14, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv2 (Conv2DTranspose)    (None, 16, 36, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 16, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 32, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv3 (Conv2DTranspose)    (None, 34, 74, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 34, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "Deconv4 (Conv2DTranspose)    (None, 36, 76, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 36, 76, 32)        0         \n",
      "_________________________________________________________________\n",
      "Deconv5 (Conv2DTranspose)    (None, 38, 78, 16)        4624      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 76, 156, 16)       0         \n",
      "_________________________________________________________________\n",
      "Deconv6 (Conv2DTranspose)    (None, 78, 158, 16)       2320      \n",
      "_________________________________________________________________\n",
      "Final (Conv2DTranspose)      (None, 80, 160, 1)        145       \n",
      "=================================================================\n",
      "Total params: 181,693\n",
      "Trainable params: 181,687\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "11487/11487 [==============================] - 183s 16ms/step - loss: 0.0324 - acc: 0.9322\n",
      "Epoch 2/10\n",
      "11487/11487 [==============================] - 172s 15ms/step - loss: 0.0121 - acc: 0.9546\n",
      "Epoch 3/10\n",
      "11487/11487 [==============================] - 172s 15ms/step - loss: 0.0100 - acc: 0.9563\n",
      "Epoch 4/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0087 - acc: 0.9577\n",
      "Epoch 5/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0074 - acc: 0.9595\n",
      "Epoch 6/10\n",
      "11487/11487 [==============================] - 172s 15ms/step - loss: 0.0067 - acc: 0.9598\n",
      "Epoch 7/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0062 - acc: 0.9602\n",
      "Epoch 8/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0059 - acc: 0.9604\n",
      "Epoch 9/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0057 - acc: 0.9605\n",
      "Epoch 10/10\n",
      "11487/11487 [==============================] - 171s 15ms/step - loss: 0.0054 - acc: 0.9607\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "curr_model_hist = fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('v0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saved_models/v0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "\n",
    "def road_lines(image):\n",
    "    # Get image ready for feeding into model\n",
    "    small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "lanes = Lanes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_1.mp4.\n",
      "Moviepy - Writing video output_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_1.mp4\n"
     ]
    }
   ],
   "source": [
    "vid_output = 'output_1.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"test_videos/challenge_1.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_2.mp4.\n",
      "Moviepy - Writing video output_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_2.mp4\n"
     ]
    }
   ],
   "source": [
    "vid_output = 'output_2.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"test_videos/challenge_2.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
